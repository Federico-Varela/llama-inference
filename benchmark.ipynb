{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51bcdd39-c119-41de-bc47-852058761f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3108ff-13ce-41da-8b11-9a95bb39598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv('tgi/bench-default.csv').assign(platform='TGI').assign(options='None'), \n",
    "                pd.read_csv('tgi/bench-quantize-bb.csv').assign(platform='TGI').assign(options='quantized w/ bitsandbytes'),\n",
    "                pd.read_csv('tgi/bench-quantize-gptq.csv').assign(platform='TGI').assign(options='quantized w/ GPTQ'),\n",
    "                pd.read_csv('exllama/bench-exllama.csv').assign(platform='text-generation-webui').assign(options='exllama'),\n",
    "                pd.read_csv('exllama/bench-ggmlcpp.csv').assign(platform='text-generation-webui').assign(options='ggml'),\n",
    "                pd.read_csv('vllm/bench-vllm.csv').assign(platform='vllm').assign(options='None'),\n",
    "                pd.read_csv('vllm/modal-examples/bench-vllm.csv').assign(platform='vllm on A100').assign(options='None')]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9cfda8d-1e43-47e9-ae62-dd2d828e55ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok_count</th>\n",
       "      <th>time</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>note</th>\n",
       "      <th>platform</th>\n",
       "      <th>options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>9.462407</td>\n",
       "      <td>Write a Rust function that performs binary exp...</td>\n",
       "      <td>\\n\\n## Examples\\n\\n```rust\\nexponentiate(2, 3)...</td>\n",
       "      <td>default --model-id meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>TGI</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>9.463722</td>\n",
       "      <td>What are the differences between Javascript an...</td>\n",
       "      <td>\\nPython is a high-level programming language ...</td>\n",
       "      <td>default --model-id meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>TGI</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>9.462912</td>\n",
       "      <td>Write a story in the style of James Joyce abou...</td>\n",
       "      <td>\\nWrite a story in the style of James Joyce ab...</td>\n",
       "      <td>default --model-id meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>TGI</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>9.499037</td>\n",
       "      <td>Who does Harry turn into a balloon?</td>\n",
       "      <td>\\nWho does Harry turn into a balloon? Harry Po...</td>\n",
       "      <td>default --model-id meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>TGI</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>9.482863</td>\n",
       "      <td>Write a tale about a time-traveling historian ...</td>\n",
       "      <td>\\nWrite a tale about a time-traveling historia...</td>\n",
       "      <td>default --model-id meta-llama/Llama-2-7b-hf</td>\n",
       "      <td>TGI</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tok_count      time                                           question  \\\n",
       "0        200  9.462407  Write a Rust function that performs binary exp...   \n",
       "1        200  9.463722  What are the differences between Javascript an...   \n",
       "2        200  9.462912  Write a story in the style of James Joyce abou...   \n",
       "3        200  9.499037                Who does Harry turn into a balloon?   \n",
       "4        200  9.482863  Write a tale about a time-traveling historian ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  \\n\\n## Examples\\n\\n```rust\\nexponentiate(2, 3)...   \n",
       "1  \\nPython is a high-level programming language ...   \n",
       "2  \\nWrite a story in the style of James Joyce ab...   \n",
       "3  \\nWho does Harry turn into a balloon? Harry Po...   \n",
       "4  \\nWrite a tale about a time-traveling historia...   \n",
       "\n",
       "                                          note platform options  \n",
       "0  default --model-id meta-llama/Llama-2-7b-hf      TGI    None  \n",
       "1  default --model-id meta-llama/Llama-2-7b-hf      TGI    None  \n",
       "2  default --model-id meta-llama/Llama-2-7b-hf      TGI    None  \n",
       "3  default --model-id meta-llama/Llama-2-7b-hf      TGI    None  \n",
       "4  default --model-id meta-llama/Llama-2-7b-hf      TGI    None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9ddd3c9-4c2a-4015-a181-142defd5fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tok/sec'] = df['tok_count'] / df['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e28de92-84ce-4713-8482-f4da750baa84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tok/sec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform</th>\n",
       "      <th>options</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">TGI</th>\n",
       "      <th>None</th>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantized w/ GPTQ</th>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantized w/ bitsandbytes</th>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">text-generation-webui</th>\n",
       "      <th>exllama</th>\n",
       "      <td>30.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ggml</th>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vllm</th>\n",
       "      <th>None</th>\n",
       "      <td>46.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vllm on A100</th>\n",
       "      <th>None</th>\n",
       "      <td>40.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tok/sec\n",
       "platform              options                           \n",
       "TGI                   None                          21.1\n",
       "                      quantized w/ GPTQ             23.6\n",
       "                      quantized w/ bitsandbytes      1.9\n",
       "text-generation-webui exllama                       30.8\n",
       "                      ggml                           9.9\n",
       "vllm                  None                          46.3\n",
       "vllm on A100          None                          40.9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.precision', 1)\n",
    "df.groupby(['platform', 'options']).mean('time')[['tok/sec']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c7508-581e-4d11-b906-b3c557fbac4d",
   "metadata": {},
   "source": [
    "Why is quantization slower for `bits and bytes`?  Someone else [mentioned it here](https://github.com/huggingface/text-generation-inference/issues/309) and says that it is well known that it is slow!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b256b4c9-623c-4950-9e2b-60e19857f4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
