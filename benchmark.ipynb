{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bcdd39-c119-41de-bc47-852058761f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3108ff-13ce-41da-8b11-9a95bb39598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv('hf-endpoint/bench-hf-endpoint.csv').assign(platform='Inference Endpoint (A10G)').assign(options='-'),\n",
    "                pd.read_csv('tgi/bench-default.csv').assign(platform='TGI').assign(options='-'), \n",
    "                pd.read_csv('tgi/bench-quantize-bb.csv').assign(platform='TGI').assign(options='quantized w/ bitsandbytes'),\n",
    "                pd.read_csv('tgi/bench-quantize-gptq.csv').assign(platform='TGI').assign(options='quantized w/ GPTQ'),\n",
    "                pd.read_csv('exllama/bench-exllama.csv').assign(platform='text-generation-webui').assign(options='exllama'),\n",
    "                pd.read_csv('exllama/bench-ggmlcpp.csv').assign(platform='text-generation-webui').assign(options='ggml'),\n",
    "                pd.read_csv('vllm/bench-vllm.csv').assign(platform='vllm').assign(options='-'),\n",
    "                pd.read_csv('vllm/modal-examples/bench-vllm.csv').assign(platform='vllm on A100').assign(options='-')]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cfda8d-1e43-47e9-ae62-dd2d828e55ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok_count</th>\n",
       "      <th>time</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>note</th>\n",
       "      <th>platform</th>\n",
       "      <th>options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Write a Rust function that performs binary exp...</td>\n",
       "      <td>\\n\\n## Examples\\n\\n```rust\\nexponentiate(2, 3)...</td>\n",
       "      <td>hf-endpoint</td>\n",
       "      <td>Inference Endpoint (A10G)</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>6.9</td>\n",
       "      <td>What are the differences between Javascript an...</td>\n",
       "      <td>\\nPython is a high-level programming language ...</td>\n",
       "      <td>hf-endpoint</td>\n",
       "      <td>Inference Endpoint (A10G)</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Write a story in the style of James Joyce abou...</td>\n",
       "      <td>\\nWrite a story in the style of James Joyce ab...</td>\n",
       "      <td>hf-endpoint</td>\n",
       "      <td>Inference Endpoint (A10G)</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Who does Harry turn into a balloon?</td>\n",
       "      <td>\\nWho does Harry turn into a balloon? Harry Po...</td>\n",
       "      <td>hf-endpoint</td>\n",
       "      <td>Inference Endpoint (A10G)</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Write a tale about a time-traveling historian ...</td>\n",
       "      <td>\\nWrite a tale about a time-traveling historia...</td>\n",
       "      <td>hf-endpoint</td>\n",
       "      <td>Inference Endpoint (A10G)</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tok_count  time                                           question  \\\n",
       "0        202   6.6  Write a Rust function that performs binary exp...   \n",
       "1        202   6.9  What are the differences between Javascript an...   \n",
       "2        202   6.6  Write a story in the style of James Joyce abou...   \n",
       "3        202   6.6                Who does Harry turn into a balloon?   \n",
       "4        202   6.6  Write a tale about a time-traveling historian ...   \n",
       "\n",
       "                                              answer         note  \\\n",
       "0  \\n\\n## Examples\\n\\n```rust\\nexponentiate(2, 3)...  hf-endpoint   \n",
       "1  \\nPython is a high-level programming language ...  hf-endpoint   \n",
       "2  \\nWrite a story in the style of James Joyce ab...  hf-endpoint   \n",
       "3  \\nWho does Harry turn into a balloon? Harry Po...  hf-endpoint   \n",
       "4  \\nWrite a tale about a time-traveling historia...  hf-endpoint   \n",
       "\n",
       "                    platform options  \n",
       "0  Inference Endpoint (A10G)       -  \n",
       "1  Inference Endpoint (A10G)       -  \n",
       "2  Inference Endpoint (A10G)       -  \n",
       "3  Inference Endpoint (A10G)       -  \n",
       "4  Inference Endpoint (A10G)       -  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ddd3c9-4c2a-4015-a181-142defd5fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tok/sec'] = df['tok_count'] / df['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28de92-84ce-4713-8482-f4da750baa84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tok/sec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform</th>\n",
       "      <th>options</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Inference Endpoint (A10G)</th>\n",
       "      <th>-</th>\n",
       "      <td>30.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">TGI</th>\n",
       "      <th>-</th>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantized w/ GPTQ</th>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantized w/ bitsandbytes</th>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">text-generation-webui</th>\n",
       "      <th>exllama</th>\n",
       "      <td>30.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ggml</th>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vllm</th>\n",
       "      <th>-</th>\n",
       "      <td>46.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vllm on A100</th>\n",
       "      <th>-</th>\n",
       "      <td>40.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tok/sec\n",
       "platform                  options                           \n",
       "Inference Endpoint (A10G) -                             30.4\n",
       "TGI                       -                             21.1\n",
       "                          quantized w/ GPTQ             23.6\n",
       "                          quantized w/ bitsandbytes      1.9\n",
       "text-generation-webui     exllama                       30.8\n",
       "                          ggml                           9.9\n",
       "vllm                      -                             46.3\n",
       "vllm on A100              -                             40.9"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.precision', 1)\n",
    "df.groupby(['platform', 'options']).mean('time')[['tok/sec']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c7508-581e-4d11-b906-b3c557fbac4d",
   "metadata": {},
   "source": [
    "Why is quantization slower for `bits and bytes`?  Someone else [mentioned it here](https://github.com/huggingface/text-generation-inference/issues/309) and says that it is well known that it is slow!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b256b4c9-623c-4950-9e2b-60e19857f4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
